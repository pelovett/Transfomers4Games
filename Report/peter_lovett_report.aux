\relax 
\citation{mnih2013playing}
\citation{watkins1992q}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Deep Q-Learning}{1}}
\citation{brockman2016openai}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Pretraining}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The transformer model used for observation prediction. Here the two white layers are the input and output, while the blue layers are the model itself. All layers except for the last feedforward layer were used at test time.}}{3}}
\newlabel{fig:diagram}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This chart displays the results of using an RNN to encode the relevant information in the environment with varying embedding sizes. Here the y-axis is the trailing average for the total reward from the last 100 episodes.}}{3}}
\newlabel{fig:naive_rnn}{{2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces This chart displays the results of using a Transformer to encode the relevant information in the environment with varying embedding sizes. Here the y-axis is the trailing average for the total reward from the last 100 episodes.}}{3}}
\newlabel{fig:naive_transformer}{{3}{3}}
\bibdata{proposal}
\bibcite{brockman2016openai}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces This chart displays the results of using an RNN to encode the relevant information in the environment with varying embedding sizes. Here the y-axis is the trailing average for the total reward from the last 100 episodes.}}{4}}
\newlabel{fig:smart_rnn}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces This chart displays the results of using a Transformer to encode the relevant information in the environment with varying embedding sizes. Here the y-axis is the trailing average for the total reward from the last 100 episodes.}}{4}}
\newlabel{fig:smart_transformer}{{5}{4}}
\bibcite{mnih2013playing}{2}
\bibcite{watkins1992q}{3}
\bibstyle{abbrv}
